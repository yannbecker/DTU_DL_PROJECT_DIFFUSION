{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "403059ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluations2 import compute_kl, compute_mmd, compute_wasserstein, compute_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4225d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original matrix shape: (100, 3)\n",
      "Generated matrix shape: (100, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_dummy_data(n_samples: int = 100, seed: int = 42) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Génère deux matrices NumPy (Original et Generated) de taille (n_samples, 3)\n",
    "    avec des relations polynomiales et du bruit.\n",
    "\n",
    "    Args:\n",
    "        n_samples: Nombre d'observations (lignes).\n",
    "        seed: Graine pour la reproductibilité.\n",
    "\n",
    "    Returns:\n",
    "        Un tuple contenant (Original_data, Generated_data).\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # --- 1. Génération des données de base (Original) ---\n",
    "    # Création d'une variable de base x (de 0 à 10 pour l'exemple)\n",
    "    x = np.linspace(0, 10, n_samples)\n",
    "\n",
    "    # Définition des 3 features (relations polynomiales)\n",
    "    feature_1 = x                 # F1: Linéaire (x)\n",
    "    feature_2 = x**2              # F2: Quadratique (x^2)\n",
    "    feature_3 = x**3              # F3: Cubique (x^3)\n",
    "\n",
    "    # Assemblage de la matrice Original (sans ordre)\n",
    "    original_data_ordered = np.column_stack((feature_1, feature_2, feature_3))\n",
    "\n",
    "    # Mélange des lignes (observations) pour casser l'ordre initial\n",
    "    # np.random.permutation renvoie un nouvel ordre d'indices\n",
    "    shuffle_indices = np.random.permutation(n_samples)\n",
    "    Original = original_data_ordered[shuffle_indices]\n",
    "\n",
    "\n",
    "    # --- 2. Génération des données bruitées (Generated) ---\n",
    "    # On reprend les données Original (ordonnées) pour s'assurer que le bruit est appliqué\n",
    "    # sur la même base\n",
    "    Generated_base = original_data_ordered.copy()\n",
    "\n",
    "    # Ajout du bruit (Gaussien) pour simuler la génération/transformation\n",
    "    # L'échelle du bruit est ajustée pour être pertinente par rapport aux données\n",
    "    scale_f1 = np.std(feature_1) * 0.3  # 10% de l'écart-type de F1\n",
    "    scale_f2 = np.std(feature_2) * 0.4  # 10% de l'écart-type de F2\n",
    "    scale_f3 = np.std(feature_3) * 0.1 # 5% de l'écart-type de F3 (car x^3 est plus grand)\n",
    "\n",
    "    # Ajout du bruit différent pour chaque colonne\n",
    "    noise_f1 = np.random.normal(0, scale_f1, n_samples)\n",
    "    noise_f2 = np.random.normal(0, scale_f2, n_samples)\n",
    "    noise_f3 = np.random.normal(0, scale_f3, n_samples)\n",
    "\n",
    "    Generated_base[:, 0] += noise_f1\n",
    "    Generated_base[:, 1] += noise_f2\n",
    "    Generated_base[:, 2] += noise_f3\n",
    "\n",
    "    # Mélange des lignes de Generated (en utilisant les mêmes indices pour la cohérence,\n",
    "    # mais n'est pas strictement nécessaire pour la mesure des métriques)\n",
    "    Generated = Generated_base[shuffle_indices]\n",
    "\n",
    "    print(f\"Original matrix shape: {Original.shape}\")\n",
    "    print(f\"Generated matrix shape: {Generated.shape}\")\n",
    "    \n",
    "    return Original, Generated\n",
    "\n",
    "# --- Exécution ---\n",
    "Original_data, Generated_data = generate_dummy_data(n_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a665afb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thiba\\OneDrive\\Documents\\DTU\\Deep Learning\\Lab4&5&6\\Deep_Learning_Lab4\\Lib\\site-packages\\legacy_api_wrap\\__init__.py:88: FutureWarning: The dtype argument is deprecated and will be removed in late 2024.\n",
      "  return fn(*args_all, **kw)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcompute_random_forest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOriginal_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgenerated\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGenerated_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfigure_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mroc_curve.png\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thiba\\OneDrive\\Documents\\DTU\\Deep Learning\\Lab4&5&6\\Project\\DTU_DL_PROJECT_DIFFUSION\\src\\metrics\\evaluations2.py:144\u001b[39m, in \u001b[36mcompute_random_forest\u001b[39m\u001b[34m(original, generated, output_path, figure_name, n_estimators, max_depth, oob_score, class_weight, random_state)\u001b[39m\n\u001b[32m    142\u001b[39m full_data.obs_names = [\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtrue_Cell\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(original.shape[\u001b[32m0\u001b[39m])]+[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mgen_Cell\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(generated.shape[\u001b[32m0\u001b[39m])]\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m#sc.tl.pca(adata, svd_solver='arpack') # svd_solver \u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m real = \u001b[43madata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mobsm\u001b[49m\u001b[43m[\u001b[49m\u001b[43madata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mobs_names\u001b[49m\u001b[43m==\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrue_Cell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    145\u001b[39m sim = adata.obsm[adata.obs_names== \u001b[33m\"\u001b[39m\u001b[33mgen_Cell\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    147\u001b[39m data = np.concatenate((real,sim),axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thiba\\OneDrive\\Documents\\DTU\\Deep Learning\\Lab4&5&6\\Deep_Learning_Lab4\\Lib\\site-packages\\anndata\\_core\\aligned_mapping.py:215\u001b[39m, in \u001b[36mAlignedActual.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) -> Value:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "compute_random_forest(\n",
    "    original=Original_data,\n",
    "    generated=Generated_data,\n",
    "    output_path=\"./\",\n",
    "    figure_name=\"roc_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb262ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.00285076)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_kl(original=Original_data, generated=Generated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7de68704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.40526869043339"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_wasserstein(original=Original_data, generated=Generated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edfc9192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.02836536)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_mmd(original=Original_data, generated=Generated_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep_Learning_Lab4 (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
